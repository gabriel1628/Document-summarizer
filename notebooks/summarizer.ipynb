{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "f30b68b7",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_core.output_parsers import StrOutputParser\n",
    "from langchain_core.prompts import PromptTemplate\n",
    "from langchain_text_splitters import RecursiveCharacterTextSplitter\n",
    "from langchain.chains.summarize import load_summarize_chain\n",
    "from langchain_community.document_loaders.text import TextLoader\n",
    "from langchain_mistralai import ChatMistralAI\n",
    "from IPython.display import Markdown, display\n",
    "from dotenv import dotenv_values\n",
    "environment_variables = dotenv_values()\n",
    "OPENAI_API_KEY = environment_variables[\"OPENAI_API_KEY\"]\n",
    "MISTRAL_API_KEY = environment_variables[\"MISTRAL_API_KEY\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "65575688",
   "metadata": {},
   "source": [
    "# Summarize a single document"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "c2d40bb2",
   "metadata": {},
   "outputs": [],
   "source": [
    "text = TextLoader(\"../test_documents/sample_text.txt\").load()[0]\n",
    "# display(Markdown(text.page_content))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "256f1e92",
   "metadata": {},
   "outputs": [],
   "source": [
    "llm = ChatMistralAI(model=\"mistral-small-latest\", temperature=0.3, api_key=MISTRAL_API_KEY)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "0eb7817d",
   "metadata": {},
   "outputs": [],
   "source": [
    "prompt_template = \"\"\"\n",
    "Write a comprehensive summary of the following text. The summary should:\n",
    "1. Highlight the main points and key ideas\n",
    "2. Include important details and supporting evidence\n",
    "3. Maintain the original meaning and intent\n",
    "4. Be well-structured and coherent\n",
    "\n",
    "Text to summarize:\n",
    "{text}\n",
    "\n",
    "Comprehensive Summary:\n",
    "\"\"\"\n",
    "prompt = PromptTemplate(template=prompt_template, input_variables=[\"text\"])\n",
    "chain = prompt | llm | StrOutputParser()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "69111b3b",
   "metadata": {},
   "outputs": [],
   "source": [
    "summary = chain.invoke({\"text\": text})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "e73bdf73",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "### Comprehensive Summary of Data Processing Engines: Ray, Dask, and Apache Spark\n",
       "\n",
       "#### Introduction\n",
       "This summary compares and provides an integrated overview of three prominent data processing engines: Ray, Dask, and Apache Spark. Each engine is evaluated based on its core functionalities, performance capabilities, and ideal use cases in data science and machine learning (ML). The insights are drawn from various analyses, webinars, and blog posts discussing the evolution of machine learning too"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Markdown(summary[:500])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "108efd0d",
   "metadata": {},
   "source": [
    "# Summarize multiple documents"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "f330d8ba",
   "metadata": {},
   "outputs": [],
   "source": [
    "text_splitter = RecursiveCharacterTextSplitter(\n",
    "    chunk_size=4000, chunk_overlap=200, separators=[\"\\n\\n\", \"\\n\", \" \", \"\"]\n",
    ")\n",
    "docs = text_splitter.create_documents([text.page_content])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "fb57e1ed",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(docs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "4995dd2e",
   "metadata": {},
   "outputs": [],
   "source": [
    "map_prompt_template = \"\"\"\n",
    "Write a concise summary of the following text, focusing on the key points:\n",
    "{text}\n",
    "\n",
    "Concise Summary:\n",
    "\"\"\"\n",
    "\n",
    "combine_prompt_template = \"\"\"\n",
    "You are provided with multiple summaries from different sections of a document or article.\n",
    "Your task is to create a comprehensive, well-structured final summary that:\n",
    "1. Integrates all the important information from the individual summaries\n",
    "2. Presents a coherent overview of the entire content\n",
    "3. Organizes the information logically with appropriate headings and structure\n",
    "4. Eliminates redundancy while preserving important details\n",
    "\n",
    "Individual summaries:\n",
    "{text}\n",
    "\n",
    "Comprehensive Final Summary:\n",
    "\"\"\"\n",
    "\n",
    "map_prompt = PromptTemplate(\n",
    "    template=map_prompt_template, input_variables=[\"text\"]\n",
    ")\n",
    "combine_prompt = PromptTemplate(\n",
    "    template=combine_prompt_template, input_variables=[\"text\"]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "355744e5",
   "metadata": {},
   "outputs": [],
   "source": [
    "summary_chain = load_summarize_chain(\n",
    "    llm,\n",
    "    chain_type=\"map_reduce\",\n",
    "    map_prompt=map_prompt,\n",
    "    combine_prompt=combine_prompt,\n",
    "    verbose=False,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "9817f540",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/gabriel/Documents/Git/Document summarizer/.venv/lib/python3.11/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n",
      "\n",
      "A module that was compiled using NumPy 1.x cannot be run in\n",
      "NumPy 2.2.4 as it may crash. To support both 1.x and 2.x\n",
      "versions of NumPy, modules must be compiled with NumPy 2.0.\n",
      "Some module may need to rebuild instead e.g. with 'pybind11>=2.12'.\n",
      "\n",
      "If you are a user of the module, the easiest solution will be to\n",
      "downgrade to 'numpy<2' or try to upgrade the affected module.\n",
      "We expect that some modules will need time to support NumPy 2.\n",
      "\n",
      "Traceback (most recent call last):  File \"<frozen runpy>\", line 198, in _run_module_as_main\n",
      "  File \"<frozen runpy>\", line 88, in _run_code\n",
      "  File \"/Users/gabriel/Documents/Git/Document summarizer/.venv/lib/python3.11/site-packages/ipykernel_launcher.py\", line 18, in <module>\n",
      "    app.launch_new_instance()\n",
      "  File \"/Users/gabriel/Documents/Git/Document summarizer/.venv/lib/python3.11/site-packages/traitlets/config/application.py\", line 1075, in launch_instance\n",
      "    app.start()\n",
      "  File \"/Users/gabriel/Documents/Git/Document summarizer/.venv/lib/python3.11/site-packages/ipykernel/kernelapp.py\", line 739, in start\n",
      "    self.io_loop.start()\n",
      "  File \"/Users/gabriel/Documents/Git/Document summarizer/.venv/lib/python3.11/site-packages/tornado/platform/asyncio.py\", line 205, in start\n",
      "    self.asyncio_loop.run_forever()\n",
      "  File \"/Users/gabriel/.local/share/uv/python/cpython-3.11.11-macos-x86_64-none/lib/python3.11/asyncio/base_events.py\", line 608, in run_forever\n",
      "    self._run_once()\n",
      "  File \"/Users/gabriel/.local/share/uv/python/cpython-3.11.11-macos-x86_64-none/lib/python3.11/asyncio/base_events.py\", line 1936, in _run_once\n",
      "    handle._run()\n",
      "  File \"/Users/gabriel/.local/share/uv/python/cpython-3.11.11-macos-x86_64-none/lib/python3.11/asyncio/events.py\", line 84, in _run\n",
      "    self._context.run(self._callback, *self._args)\n",
      "  File \"/Users/gabriel/Documents/Git/Document summarizer/.venv/lib/python3.11/site-packages/ipykernel/kernelbase.py\", line 545, in dispatch_queue\n",
      "    await self.process_one()\n",
      "  File \"/Users/gabriel/Documents/Git/Document summarizer/.venv/lib/python3.11/site-packages/ipykernel/kernelbase.py\", line 534, in process_one\n",
      "    await dispatch(*args)\n",
      "  File \"/Users/gabriel/Documents/Git/Document summarizer/.venv/lib/python3.11/site-packages/ipykernel/kernelbase.py\", line 437, in dispatch_shell\n",
      "    await result\n",
      "  File \"/Users/gabriel/Documents/Git/Document summarizer/.venv/lib/python3.11/site-packages/ipykernel/ipkernel.py\", line 362, in execute_request\n",
      "    await super().execute_request(stream, ident, parent)\n",
      "  File \"/Users/gabriel/Documents/Git/Document summarizer/.venv/lib/python3.11/site-packages/ipykernel/kernelbase.py\", line 778, in execute_request\n",
      "    reply_content = await reply_content\n",
      "  File \"/Users/gabriel/Documents/Git/Document summarizer/.venv/lib/python3.11/site-packages/ipykernel/ipkernel.py\", line 449, in do_execute\n",
      "    res = shell.run_cell(\n",
      "  File \"/Users/gabriel/Documents/Git/Document summarizer/.venv/lib/python3.11/site-packages/ipykernel/zmqshell.py\", line 549, in run_cell\n",
      "    return super().run_cell(*args, **kwargs)\n",
      "  File \"/Users/gabriel/Documents/Git/Document summarizer/.venv/lib/python3.11/site-packages/IPython/core/interactiveshell.py\", line 3098, in run_cell\n",
      "    result = self._run_cell(\n",
      "  File \"/Users/gabriel/Documents/Git/Document summarizer/.venv/lib/python3.11/site-packages/IPython/core/interactiveshell.py\", line 3153, in _run_cell\n",
      "    result = runner(coro)\n",
      "  File \"/Users/gabriel/Documents/Git/Document summarizer/.venv/lib/python3.11/site-packages/IPython/core/async_helpers.py\", line 128, in _pseudo_sync_runner\n",
      "    coro.send(None)\n",
      "  File \"/Users/gabriel/Documents/Git/Document summarizer/.venv/lib/python3.11/site-packages/IPython/core/interactiveshell.py\", line 3362, in run_cell_async\n",
      "    has_raised = await self.run_ast_nodes(code_ast.body, cell_name,\n",
      "  File \"/Users/gabriel/Documents/Git/Document summarizer/.venv/lib/python3.11/site-packages/IPython/core/interactiveshell.py\", line 3607, in run_ast_nodes\n",
      "    if await self.run_code(code, result, async_=asy):\n",
      "  File \"/Users/gabriel/Documents/Git/Document summarizer/.venv/lib/python3.11/site-packages/IPython/core/interactiveshell.py\", line 3667, in run_code\n",
      "    exec(code_obj, self.user_global_ns, self.user_ns)\n",
      "  File \"/var/folders/n2/76d5x8592dl18hpmjm7c4_tw0000gp/T/ipykernel_33869/2353815681.py\", line 1, in <module>\n",
      "    result = summary_chain.invoke(docs)\n",
      "  File \"/Users/gabriel/Documents/Git/Document summarizer/.venv/lib/python3.11/site-packages/langchain/chains/base.py\", line 160, in invoke\n",
      "    self._call(inputs, run_manager=run_manager)\n",
      "  File \"/Users/gabriel/Documents/Git/Document summarizer/.venv/lib/python3.11/site-packages/langchain/chains/combine_documents/base.py\", line 138, in _call\n",
      "    output, extra_return_dict = self.combine_docs(\n",
      "  File \"/Users/gabriel/Documents/Git/Document summarizer/.venv/lib/python3.11/site-packages/langchain/chains/combine_documents/map_reduce.py\", line 251, in combine_docs\n",
      "    result, extra_return_dict = self.reduce_documents_chain.combine_docs(\n",
      "  File \"/Users/gabriel/Documents/Git/Document summarizer/.venv/lib/python3.11/site-packages/langchain/chains/combine_documents/reduce.py\", line 252, in combine_docs\n",
      "    result_docs, extra_return_dict = self._collapse(\n",
      "  File \"/Users/gabriel/Documents/Git/Document summarizer/.venv/lib/python3.11/site-packages/langchain/chains/combine_documents/reduce.py\", line 297, in _collapse\n",
      "    num_tokens = length_func(result_docs, **kwargs)\n",
      "  File \"/Users/gabriel/Documents/Git/Document summarizer/.venv/lib/python3.11/site-packages/langchain/chains/combine_documents/stuff.py\", line 241, in prompt_length\n",
      "    return self.llm_chain._get_num_tokens(prompt)\n",
      "  File \"/Users/gabriel/Documents/Git/Document summarizer/.venv/lib/python3.11/site-packages/langchain/chains/llm.py\", line 409, in _get_num_tokens\n",
      "    return _get_language_model(self.llm).get_num_tokens(text)\n",
      "  File \"/Users/gabriel/Documents/Git/Document summarizer/.venv/lib/python3.11/site-packages/langchain_core/language_models/base.py\", line 366, in get_num_tokens\n",
      "    return len(self.get_token_ids(text))\n",
      "  File \"/Users/gabriel/Documents/Git/Document summarizer/.venv/lib/python3.11/site-packages/langchain_core/language_models/base.py\", line 353, in get_token_ids\n",
      "    return _get_token_ids_default_method(text)\n",
      "  File \"/Users/gabriel/Documents/Git/Document summarizer/.venv/lib/python3.11/site-packages/langchain_core/language_models/base.py\", line 79, in _get_token_ids_default_method\n",
      "    tokenizer = get_tokenizer()\n",
      "  File \"/Users/gabriel/Documents/Git/Document summarizer/.venv/lib/python3.11/site-packages/langchain_core/language_models/base.py\", line 64, in get_tokenizer\n",
      "    from transformers import GPT2TokenizerFast  # type: ignore[import-not-found]\n",
      "  File \"/Users/gabriel/Documents/Git/Document summarizer/.venv/lib/python3.11/site-packages/transformers/__init__.py\", line 26, in <module>\n",
      "    from . import dependency_versions_check\n",
      "  File \"/Users/gabriel/Documents/Git/Document summarizer/.venv/lib/python3.11/site-packages/transformers/dependency_versions_check.py\", line 16, in <module>\n",
      "    from .utils.versions import require_version, require_version_core\n",
      "  File \"/Users/gabriel/Documents/Git/Document summarizer/.venv/lib/python3.11/site-packages/transformers/utils/__init__.py\", line 25, in <module>\n",
      "    from .chat_template_utils import DocstringParsingException, TypeHintParsingException, get_json_schema\n",
      "  File \"/Users/gabriel/Documents/Git/Document summarizer/.venv/lib/python3.11/site-packages/transformers/utils/chat_template_utils.py\", line 40, in <module>\n",
      "    from torch import Tensor\n",
      "  File \"/Users/gabriel/Documents/Git/Document summarizer/.venv/lib/python3.11/site-packages/torch/__init__.py\", line 1477, in <module>\n",
      "    from .functional import *  # noqa: F403\n",
      "  File \"/Users/gabriel/Documents/Git/Document summarizer/.venv/lib/python3.11/site-packages/torch/functional.py\", line 9, in <module>\n",
      "    import torch.nn.functional as F\n",
      "  File \"/Users/gabriel/Documents/Git/Document summarizer/.venv/lib/python3.11/site-packages/torch/nn/__init__.py\", line 1, in <module>\n",
      "    from .modules import *  # noqa: F403\n",
      "  File \"/Users/gabriel/Documents/Git/Document summarizer/.venv/lib/python3.11/site-packages/torch/nn/modules/__init__.py\", line 35, in <module>\n",
      "    from .transformer import TransformerEncoder, TransformerDecoder, \\\n",
      "  File \"/Users/gabriel/Documents/Git/Document summarizer/.venv/lib/python3.11/site-packages/torch/nn/modules/transformer.py\", line 20, in <module>\n",
      "    device: torch.device = torch.device(torch._C._get_default_device()),  # torch.device('cpu'),\n",
      "/Users/gabriel/Documents/Git/Document summarizer/.venv/lib/python3.11/site-packages/torch/nn/modules/transformer.py:20: UserWarning: Failed to initialize NumPy: _ARRAY_API not found (Triggered internally at /Users/runner/work/pytorch/pytorch/pytorch/torch/csrc/utils/tensor_numpy.cpp:84.)\n",
      "  device: torch.device = torch.device(torch._C._get_default_device()),  # torch.device('cpu'),\n"
     ]
    }
   ],
   "source": [
    "result = summary_chain.invoke(docs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "07f1543f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dict_keys(['input_documents', 'output_text'])"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "result.keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "4c800590",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "### Comprehensive Summary of Data Processing Engines: Ray, Dask, and Apache Spark\n",
       "\n",
       "#### Overview\n",
       "This document compares three prominent data processing engines—Ray, Dask, and Apache Spark—focusing on their core functionalities, performance, scalability, and ideal use cases in data science and machine learning.\n",
       "\n",
       "#### Core Functionalities and Strengths\n",
       "\n",
       "##### Ray\n",
       "- **Strengths**: Known for ease of use, efficient distributed applications, and strong performance in reinforcement and deep learning.\n",
       "-"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Markdown(result[\"output_text\"][:500])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "20faff22",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
